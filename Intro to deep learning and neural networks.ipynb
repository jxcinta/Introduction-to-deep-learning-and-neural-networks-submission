{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('concrete_data.csv') \n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating target data and what data is the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] \n",
    "target = concrete_data['Strength'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "n_cols = predictors.shape[1] \n",
    "print(n_cols) #checking everything is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the model with one hidden layer with 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Louis\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "721/721 [==============================] - 0s 159us/step - loss: 8202.7590\n",
      "Epoch 2/50\n",
      "721/721 [==============================] - 0s 21us/step - loss: 5453.9008\n",
      "Epoch 3/50\n",
      "721/721 [==============================] - 0s 146us/step - loss: 4719.3001\n",
      "Epoch 4/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 4213.7579\n",
      "Epoch 5/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 3836.2884\n",
      "Epoch 6/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 3394.4178\n",
      "Epoch 7/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 3040.9181\n",
      "Epoch 8/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 2742.7958\n",
      "Epoch 9/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 2483.0343\n",
      "Epoch 10/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 2237.9783\n",
      "Epoch 11/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 2027.0480\n",
      "Epoch 12/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1843.9152\n",
      "Epoch 13/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 1686.3996\n",
      "Epoch 14/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1533.1856\n",
      "Epoch 15/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1389.4325\n",
      "Epoch 16/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1274.6496\n",
      "Epoch 17/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1161.6543\n",
      "Epoch 18/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1064.6142\n",
      "Epoch 19/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 980.2666\n",
      "Epoch 20/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 900.0111\n",
      "Epoch 21/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 841.3360\n",
      "Epoch 22/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 777.1635\n",
      "Epoch 23/50\n",
      "721/721 [==============================] - 0s 29us/step - loss: 716.8683\n",
      "Epoch 24/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 691.4758\n",
      "Epoch 25/50\n",
      "721/721 [==============================] - 0s 33us/step - loss: 653.2764\n",
      "Epoch 26/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 586.2996\n",
      "Epoch 27/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 548.9835\n",
      "Epoch 28/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 516.3479\n",
      "Epoch 29/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 487.8656\n",
      "Epoch 30/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 464.2909\n",
      "Epoch 31/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 447.4228\n",
      "Epoch 32/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 418.4995\n",
      "Epoch 33/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 402.4177\n",
      "Epoch 34/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 395.9788\n",
      "Epoch 35/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 370.6192\n",
      "Epoch 36/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 354.6619\n",
      "Epoch 37/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 343.2108\n",
      "Epoch 38/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 333.7691\n",
      "Epoch 39/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 323.4971\n",
      "Epoch 40/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 332.539 - 0s 24us/step - loss: 306.8979\n",
      "Epoch 41/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 297.0397\n",
      "Epoch 42/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 289.4321\n",
      "Epoch 43/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 278.8283\n",
      "Epoch 44/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 270.5442\n",
      "Epoch 45/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 264.0850\n",
      "Epoch 46/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 258.3945\n",
      "Epoch 47/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 253.1256\n",
      "Epoch 48/50\n",
      "721/721 [==============================] - 0s 50us/step - loss: 245.5956\n",
      "Epoch 49/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 242.3519\n",
      "Epoch 50/50\n",
      "721/721 [==============================] - 0s 21us/step - loss: 235.5420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1d3e427b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)\n",
    "model = regression_model()\n",
    "epochs = 50\n",
    "model.fit(X_train, y_train, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 81us/step\n",
      "The loss value is  255.05073305395427\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"The loss value is \", loss)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  255.0507586992805 The standard deviation is  0.0\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mean = np.mean(mse)\n",
    "standard_deviation = np.std(mse)\n",
    "print(\"The mean is \", mean, \"The standard deviation is \", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.21582137419568\n",
      "130.00066452273273\n",
      "116.14489010313953\n",
      "125.99957680316419\n",
      "121.03182840192974\n",
      "121.34086648391674\n",
      "134.309751195815\n",
      "104.8440513240481\n",
      "113.99755049523412\n",
      "75.36177332115791\n",
      "58.62680828995689\n",
      "49.794329066106805\n",
      "66.32267543953213\n",
      "53.918726726643094\n",
      "50.19306239649702\n",
      "43.25574439088889\n",
      "54.33007819907179\n",
      "50.48534298251748\n",
      "45.6632475498039\n",
      "55.13660492634696\n",
      "47.54654113374482\n",
      "46.45100012720596\n",
      "47.84422120770204\n",
      "45.32515368415314\n",
      "47.19258357174574\n",
      "53.21182120116397\n",
      "49.58385699620911\n",
      "44.06773013513065\n",
      "56.3122760315929\n",
      "50.053012810864494\n",
      "56.58919720202202\n",
      "42.125900441388865\n",
      "47.99271491584654\n",
      "49.049239334550876\n",
      "49.44903282980317\n",
      "53.74528239228579\n",
      "52.29191418990348\n",
      "52.96686309518166\n",
      "46.25201792547232\n",
      "45.13610953420497\n",
      "53.453572887433\n",
      "46.74969404646494\n",
      "50.86646101621363\n",
      "52.080775634370575\n",
      "52.325438416119916\n",
      "56.029113213992815\n",
      "53.66602157543392\n",
      "50.53873038677722\n",
      "48.83064666303616\n",
      "52.36215621059381\n"
     ]
    }
   ],
   "source": [
    "runs = 50\n",
    "epochs = 50\n",
    "mse_list = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=i)\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    meansqrerror = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(meansqrerror)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean is  63.58125085175958\n",
      "The standard devation is 27.047597667560463\n"
     ]
    }
   ],
   "source": [
    "mse_list = np.array(mse_list)\n",
    "mean = np.mean(mse_list)\n",
    "standard_deviation = np.std(mse_list)\n",
    "\n",
    "print(\"the mean is \", mean)\n",
    "print(\"The standard devation is\", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "predictors.head()\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()\n",
    "n_cols = predictors_norm.shape[1] # number of predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coding below is the same as in part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 1727.2996 - val_loss: 1235.1149\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1709.0622 - val_loss: 1221.8985\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1691.2737 - val_loss: 1208.9573\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1673.9144 - val_loss: 1195.7861\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1656.1085 - val_loss: 1182.5188\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1638.0746 - val_loss: 1168.9869\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1619.5500 - val_loss: 1154.5027\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1599.8551 - val_loss: 1139.3008\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1579.4926 - val_loss: 1123.2109\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1558.0636 - val_loss: 1106.5964\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1536.0582 - val_loss: 1088.9418\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1512.7479 - val_loss: 1070.7447\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1488.4851 - val_loss: 1051.9646\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1463.3566 - val_loss: 1032.1127\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1436.9311 - val_loss: 1011.7214\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1409.6957 - val_loss: 990.8306\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1381.6836 - val_loss: 969.3688\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1352.5980 - val_loss: 947.5470\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1323.1955 - val_loss: 925.0663\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1293.0164 - val_loss: 902.1050\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1261.7834 - val_loss: 879.2987\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1230.4070 - val_loss: 856.1974\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1198.9814 - val_loss: 832.4850\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1167.0883 - val_loss: 808.6829\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1135.1106 - val_loss: 785.2982\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1103.5758 - val_loss: 760.7895\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1070.9368 - val_loss: 737.4830\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1038.9786 - val_loss: 713.9033\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1006.6736 - val_loss: 690.4384\n",
      "Epoch 30/100\n",
      " - 0s - loss: 974.2622 - val_loss: 666.2193\n",
      "Epoch 31/100\n",
      " - 0s - loss: 940.2994 - val_loss: 642.9215\n",
      "Epoch 32/100\n",
      " - 0s - loss: 906.5828 - val_loss: 618.7460\n",
      "Epoch 33/100\n",
      " - 0s - loss: 871.7445 - val_loss: 595.8003\n",
      "Epoch 34/100\n",
      " - 0s - loss: 836.8215 - val_loss: 573.2282\n",
      "Epoch 35/100\n",
      " - 0s - loss: 802.5976 - val_loss: 550.3953\n",
      "Epoch 36/100\n",
      " - 0s - loss: 767.6851 - val_loss: 529.1949\n",
      "Epoch 37/100\n",
      " - 0s - loss: 734.1982 - val_loss: 508.0077\n",
      "Epoch 38/100\n",
      " - 0s - loss: 701.5115 - val_loss: 488.1633\n",
      "Epoch 39/100\n",
      " - 0s - loss: 669.8846 - val_loss: 468.7148\n",
      "Epoch 40/100\n",
      " - 0s - loss: 638.9038 - val_loss: 450.8030\n",
      "Epoch 41/100\n",
      " - 0s - loss: 609.9008 - val_loss: 432.8173\n",
      "Epoch 42/100\n",
      " - 0s - loss: 581.2534 - val_loss: 416.3086\n",
      "Epoch 43/100\n",
      " - 0s - loss: 554.9681 - val_loss: 400.7780\n",
      "Epoch 44/100\n",
      " - 0s - loss: 529.3273 - val_loss: 385.9301\n",
      "Epoch 45/100\n",
      " - 0s - loss: 505.1594 - val_loss: 372.5454\n",
      "Epoch 46/100\n",
      " - 0s - loss: 482.4442 - val_loss: 359.5972\n",
      "Epoch 47/100\n",
      " - 0s - loss: 460.5425 - val_loss: 348.5031\n",
      "Epoch 48/100\n",
      " - 0s - loss: 440.4357 - val_loss: 336.8054\n",
      "Epoch 49/100\n",
      " - 0s - loss: 420.7214 - val_loss: 326.8868\n",
      "Epoch 50/100\n",
      " - 0s - loss: 402.6173 - val_loss: 317.3691\n",
      "Epoch 51/100\n",
      " - 0s - loss: 385.6104 - val_loss: 308.5221\n",
      "Epoch 52/100\n",
      " - 0s - loss: 369.5943 - val_loss: 300.1333\n",
      "Epoch 53/100\n",
      " - 0s - loss: 354.6304 - val_loss: 293.4835\n",
      "Epoch 54/100\n",
      " - 0s - loss: 340.6816 - val_loss: 286.3030\n",
      "Epoch 55/100\n",
      " - 0s - loss: 327.6726 - val_loss: 279.8534\n",
      "Epoch 56/100\n",
      " - 0s - loss: 315.9221 - val_loss: 273.8458\n",
      "Epoch 57/100\n",
      " - 0s - loss: 304.8295 - val_loss: 268.2590\n",
      "Epoch 58/100\n",
      " - 0s - loss: 294.4996 - val_loss: 264.1076\n",
      "Epoch 59/100\n",
      " - 0s - loss: 285.1234 - val_loss: 259.5644\n",
      "Epoch 60/100\n",
      " - 0s - loss: 276.3612 - val_loss: 255.5050\n",
      "Epoch 61/100\n",
      " - 0s - loss: 268.3575 - val_loss: 252.3967\n",
      "Epoch 62/100\n",
      " - 0s - loss: 260.7784 - val_loss: 248.8839\n",
      "Epoch 63/100\n",
      " - 0s - loss: 254.2001 - val_loss: 245.7356\n",
      "Epoch 64/100\n",
      " - 0s - loss: 247.8738 - val_loss: 243.2899\n",
      "Epoch 65/100\n",
      " - 0s - loss: 242.2656 - val_loss: 240.8995\n",
      "Epoch 66/100\n",
      " - 0s - loss: 237.1474 - val_loss: 238.4729\n",
      "Epoch 67/100\n",
      " - 0s - loss: 232.2012 - val_loss: 237.0405\n",
      "Epoch 68/100\n",
      " - 0s - loss: 227.9937 - val_loss: 235.4563\n",
      "Epoch 69/100\n",
      " - 0s - loss: 223.9756 - val_loss: 234.1016\n",
      "Epoch 70/100\n",
      " - 0s - loss: 220.3580 - val_loss: 232.4025\n",
      "Epoch 71/100\n",
      " - 0s - loss: 217.2767 - val_loss: 231.2594\n",
      "Epoch 72/100\n",
      " - 0s - loss: 214.2788 - val_loss: 230.5267\n",
      "Epoch 73/100\n",
      " - 0s - loss: 211.6850 - val_loss: 229.3390\n",
      "Epoch 74/100\n",
      " - 0s - loss: 209.2995 - val_loss: 228.3866\n",
      "Epoch 75/100\n",
      " - 0s - loss: 207.0889 - val_loss: 227.7249\n",
      "Epoch 76/100\n",
      " - 0s - loss: 205.0738 - val_loss: 226.9055\n",
      "Epoch 77/100\n",
      " - 0s - loss: 203.2656 - val_loss: 226.0736\n",
      "Epoch 78/100\n",
      " - 0s - loss: 201.3610 - val_loss: 225.5003\n",
      "Epoch 79/100\n",
      " - 0s - loss: 199.8093 - val_loss: 224.5437\n",
      "Epoch 80/100\n",
      " - 0s - loss: 198.2465 - val_loss: 223.7824\n",
      "Epoch 81/100\n",
      " - 0s - loss: 196.8543 - val_loss: 222.8977\n",
      "Epoch 82/100\n",
      " - 0s - loss: 195.3947 - val_loss: 222.3176\n",
      "Epoch 83/100\n",
      " - 0s - loss: 194.1053 - val_loss: 221.4863\n",
      "Epoch 84/100\n",
      " - 0s - loss: 192.8404 - val_loss: 220.7292\n",
      "Epoch 85/100\n",
      " - 0s - loss: 191.5691 - val_loss: 219.9228\n",
      "Epoch 86/100\n",
      " - 0s - loss: 190.3994 - val_loss: 219.4407\n",
      "Epoch 87/100\n",
      " - 0s - loss: 189.2467 - val_loss: 218.7684\n",
      "Epoch 88/100\n",
      " - 0s - loss: 188.2039 - val_loss: 217.5714\n",
      "Epoch 89/100\n",
      " - 0s - loss: 187.0323 - val_loss: 216.6480\n",
      "Epoch 90/100\n",
      " - 0s - loss: 186.0081 - val_loss: 215.3047\n",
      "Epoch 91/100\n",
      " - 0s - loss: 184.9643 - val_loss: 214.9399\n",
      "Epoch 92/100\n",
      " - 0s - loss: 183.9791 - val_loss: 213.5893\n",
      "Epoch 93/100\n",
      " - 0s - loss: 182.9145 - val_loss: 212.4132\n",
      "Epoch 94/100\n",
      " - 0s - loss: 181.9175 - val_loss: 211.9160\n",
      "Epoch 95/100\n",
      " - 0s - loss: 180.9994 - val_loss: 210.7891\n",
      "Epoch 96/100\n",
      " - 0s - loss: 180.0210 - val_loss: 209.6414\n",
      "Epoch 97/100\n",
      " - 0s - loss: 179.0406 - val_loss: 208.3868\n",
      "Epoch 98/100\n",
      " - 0s - loss: 178.1412 - val_loss: 207.5480\n",
      "Epoch 99/100\n",
      " - 0s - loss: 177.1946 - val_loss: 205.9569\n",
      "Epoch 100/100\n",
      " - 0s - loss: 176.2760 - val_loss: 204.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1d54d6ef0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = regression_model()\n",
    "model.fit(predictors_norm, target, validation_split=0.3, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "721/721 [==============================] - 0s 169us/step - loss: 1568.6494\n",
      "Epoch 2/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1553.7863\n",
      "Epoch 3/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1539.0904\n",
      "Epoch 4/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1524.6160\n",
      "Epoch 5/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1510.0097\n",
      "Epoch 6/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1495.1194\n",
      "Epoch 7/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1479.7205\n",
      "Epoch 8/50\n",
      "721/721 [==============================] - 0s 28us/step - loss: 1464.0611\n",
      "Epoch 9/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1447.7590\n",
      "Epoch 10/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1430.5315\n",
      "Epoch 11/50\n",
      "721/721 [==============================] - 0s 32us/step - loss: 1413.0214\n",
      "Epoch 12/50\n",
      "721/721 [==============================] - 0s 29us/step - loss: 1394.4512\n",
      "Epoch 13/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1375.7432\n",
      "Epoch 14/50\n",
      "721/721 [==============================] - 0s 31us/step - loss: 1355.9777\n",
      "Epoch 15/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1335.7905\n",
      "Epoch 16/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1314.8713\n",
      "Epoch 17/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1293.0217\n",
      "Epoch 18/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1270.7283\n",
      "Epoch 19/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1247.7217\n",
      "Epoch 20/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1223.6677\n",
      "Epoch 21/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1199.0931\n",
      "Epoch 22/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1173.3050\n",
      "Epoch 23/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1146.7333\n",
      "Epoch 24/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1119.1084\n",
      "Epoch 25/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1091.2098\n",
      "Epoch 26/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1061.5352\n",
      "Epoch 27/50\n",
      "721/721 [==============================] - 0s 28us/step - loss: 1031.5125\n",
      "Epoch 28/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1000.5974\n",
      "Epoch 29/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 968.6198\n",
      "Epoch 30/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 936.4684\n",
      "Epoch 31/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 904.1217\n",
      "Epoch 32/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 871.1949\n",
      "Epoch 33/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 838.5299\n",
      "Epoch 34/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 806.3191\n",
      "Epoch 35/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 773.7709\n",
      "Epoch 36/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 741.9618\n",
      "Epoch 37/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 711.4214\n",
      "Epoch 38/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 680.8843\n",
      "Epoch 39/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 651.7429\n",
      "Epoch 40/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 623.4093\n",
      "Epoch 41/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 596.3497\n",
      "Epoch 42/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 569.9780\n",
      "Epoch 43/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 544.9617\n",
      "Epoch 44/50\n",
      "721/721 [==============================] - 0s 50us/step - loss: 520.9858\n",
      "Epoch 45/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 497.9014\n",
      "Epoch 46/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 476.2120\n",
      "Epoch 47/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 330.989 - 0s 26us/step - loss: 455.2624\n",
      "Epoch 48/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 435.9444\n",
      "Epoch 49/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 417.7437\n",
      "Epoch 50/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 400.2577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1d65ab470>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)\n",
    "model = regression_model()\n",
    "epochs = 50\n",
    "model.fit(X_train, y_train, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 159us/step\n",
      "348.2635176081488\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(loss)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is  348.26350705152845 The standard deviation is  0.0\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mean = np.mean(mse)\n",
    "standard_deviation = np.std(mse)\n",
    "print(\"The mean is \", mean, \"The standard deviation is \", standard_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134.53006383902047\n",
      "121.23663379459319\n",
      "89.11513116830375\n",
      "81.3887132070597\n",
      "77.80266516725608\n",
      "82.15270272659252\n",
      "81.08279031302936\n",
      "63.664087190597186\n",
      "53.358037041228954\n",
      "42.56460963869558\n",
      "41.38982337038108\n",
      "36.21964525636346\n",
      "44.59098271490301\n",
      "44.4375544304215\n",
      "37.735594851299396\n",
      "32.83456904834142\n",
      "38.63477906285752\n",
      "38.242362772376794\n",
      "35.64140197605763\n",
      "37.267373884380056\n",
      "35.96699491828005\n",
      "35.42973829473107\n",
      "30.194590374104028\n",
      "35.1915423692623\n",
      "36.72707887297695\n",
      "38.028028148663466\n",
      "32.937688080624085\n",
      "33.67950541919103\n",
      "39.84854687687648\n",
      "38.964664483919115\n",
      "33.169738485589384\n",
      "33.31545676691247\n",
      "34.73692652631346\n",
      "35.81351974635448\n",
      "35.814026915911334\n",
      "41.51745107335952\n",
      "31.288773141632575\n",
      "37.01190089253546\n",
      "35.55421626760736\n",
      "30.978357654559186\n",
      "37.11789123140107\n",
      "30.68458472563611\n",
      "36.04292431309771\n",
      "38.90661788989811\n",
      "37.17402560039631\n",
      "38.4721679440594\n",
      "32.971416275863895\n",
      "36.24298977157444\n",
      "35.97033143892257\n",
      "38.34033356206702\n"
     ]
    }
   ],
   "source": [
    "runs = 50\n",
    "epochs = 50\n",
    "mse_list = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=i)\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    meansqrerror = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(meansqrerror)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean is  45.63963065830629\n",
      "The standard devation is 22.209460938484366\n"
     ]
    }
   ],
   "source": [
    "mse_list = np.array(mse_list)\n",
    "mean = np.mean(mse_list)\n",
    "standard_deviation = np.std(mse_list)\n",
    "\n",
    "print(\"the mean is \", mean)\n",
    "print(\"The standard devation is\", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean, mean squared error, and standard deviation have all decreased since part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "increasing epochs to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "721/721 [==============================] - 0s 183us/step - loss: 1563.1741\n",
      "Epoch 2/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1544.1043\n",
      "Epoch 3/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1524.6235\n",
      "Epoch 4/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1504.6475\n",
      "Epoch 5/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1483.6050\n",
      "Epoch 6/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1461.8289\n",
      "Epoch 7/100\n",
      "721/721 [==============================] - 0s 31us/step - loss: 1439.3914\n",
      "Epoch 8/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1415.2838\n",
      "Epoch 9/100\n",
      "721/721 [==============================] - 0s 33us/step - loss: 1390.5503\n",
      "Epoch 10/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1364.7748\n",
      "Epoch 11/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1337.8537\n",
      "Epoch 12/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 1309.8823\n",
      "Epoch 13/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 1280.6886\n",
      "Epoch 14/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 1250.6217\n",
      "Epoch 15/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1219.3065\n",
      "Epoch 16/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1186.9322\n",
      "Epoch 17/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1154.5068\n",
      "Epoch 18/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1120.5092\n",
      "Epoch 19/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1086.3596\n",
      "Epoch 20/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1051.7327\n",
      "Epoch 21/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 1016.6701\n",
      "Epoch 22/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 982.2191\n",
      "Epoch 23/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 946.9268\n",
      "Epoch 24/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 912.6241\n",
      "Epoch 25/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 878.0372\n",
      "Epoch 26/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 844.5888\n",
      "Epoch 27/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 811.3050\n",
      "Epoch 28/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 778.9418\n",
      "Epoch 29/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 746.6262\n",
      "Epoch 30/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 715.7089\n",
      "Epoch 31/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 686.2676\n",
      "Epoch 32/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 657.1861\n",
      "Epoch 33/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 629.6623\n",
      "Epoch 34/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 603.2224\n",
      "Epoch 35/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 577.8653\n",
      "Epoch 36/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 553.7568\n",
      "Epoch 37/100\n",
      "721/721 [==============================] - 0s 46us/step - loss: 530.9854\n",
      "Epoch 38/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 509.0572\n",
      "Epoch 39/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 488.4507\n",
      "Epoch 40/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 469.4001\n",
      "Epoch 41/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 450.9942\n",
      "Epoch 42/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 433.6616\n",
      "Epoch 43/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 417.5195\n",
      "Epoch 44/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 402.2324\n",
      "Epoch 45/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 388.0270\n",
      "Epoch 46/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 374.6901\n",
      "Epoch 47/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 362.4260\n",
      "Epoch 48/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 350.6975\n",
      "Epoch 49/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 340.0349\n",
      "Epoch 50/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 329.8758\n",
      "Epoch 51/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 320.3530\n",
      "Epoch 52/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 311.7624\n",
      "Epoch 53/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 303.6461\n",
      "Epoch 54/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 295.8889\n",
      "Epoch 55/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 288.7958\n",
      "Epoch 56/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 282.2467\n",
      "Epoch 57/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 276.1511\n",
      "Epoch 58/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 270.4636\n",
      "Epoch 59/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 265.0557\n",
      "Epoch 60/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 260.1438\n",
      "Epoch 61/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 255.3545\n",
      "Epoch 62/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 251.0428\n",
      "Epoch 63/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 246.9099\n",
      "Epoch 64/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 243.2299\n",
      "Epoch 65/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 239.5540\n",
      "Epoch 66/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 236.1187\n",
      "Epoch 67/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 232.9124\n",
      "Epoch 68/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 229.8074\n",
      "Epoch 69/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 226.8077\n",
      "Epoch 70/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 223.9450\n",
      "Epoch 71/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 221.3913\n",
      "Epoch 72/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 218.6883\n",
      "Epoch 73/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 216.1142\n",
      "Epoch 74/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 213.7486\n",
      "Epoch 75/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 211.3860\n",
      "Epoch 76/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 209.3160\n",
      "Epoch 77/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 207.0219\n",
      "Epoch 78/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 204.8725\n",
      "Epoch 79/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 202.9805\n",
      "Epoch 80/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 200.8142\n",
      "Epoch 81/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 198.9032\n",
      "Epoch 82/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 196.9341\n",
      "Epoch 83/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 194.9429\n",
      "Epoch 84/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 193.0896\n",
      "Epoch 85/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 191.3217\n",
      "Epoch 86/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 189.4794\n",
      "Epoch 87/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 187.6850\n",
      "Epoch 88/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 185.9934\n",
      "Epoch 89/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 184.3026\n",
      "Epoch 90/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 182.6466\n",
      "Epoch 91/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 181.1109\n",
      "Epoch 92/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 179.7224\n",
      "Epoch 93/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 178.2261\n",
      "Epoch 94/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 176.8999\n",
      "Epoch 95/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 175.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 174.2302\n",
      "Epoch 97/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 172.9646\n",
      "Epoch 98/100\n",
      "721/721 [==============================] - 0s 22us/step - loss: 171.6746\n",
      "Epoch 99/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 170.5746\n",
      "Epoch 100/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 169.3779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1d6913fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part C\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)\n",
    "model = regression_model()\n",
    "epochs = 100\n",
    "model.fit(X_train, y_train, epochs=epochs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 230us/step\n",
      "Loss value is 167.2358600900397\n",
      "The mean is  167.23586637612993 The standard deviation is  0.0\n"
     ]
    }
   ],
   "source": [
    "loss_val = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Loss value is\", loss_val)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mean = np.mean(mse)\n",
    "standard_deviation = np.std(mse)\n",
    "print(\"The mean is \", mean, \"The standard deviation is \", standard_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.74266007803018\n",
      "124.97004995994197\n",
      "99.39872702194263\n",
      "101.74721769067462\n",
      "96.17022280399853\n",
      "86.90593047898179\n",
      "92.7349467848497\n",
      "73.32610217344414\n",
      "78.46508448332258\n",
      "67.38800215489655\n",
      "66.75342211677032\n",
      "58.12056876617728\n",
      "66.21807015675171\n",
      "67.15180929733326\n",
      "61.72696185806423\n",
      "46.89229393622636\n",
      "54.70179309042526\n",
      "53.481121458281976\n",
      "48.43920276234451\n",
      "53.72708636040055\n",
      "44.95641277523102\n",
      "49.71202760221117\n",
      "45.426935078642515\n",
      "45.08976248089935\n",
      "46.3082960801603\n",
      "45.62898227234874\n",
      "44.92810389447752\n",
      "42.53113284311634\n",
      "48.764087812800234\n",
      "46.484016973995466\n",
      "47.32573486377506\n",
      "42.862715174850905\n",
      "42.86626004709781\n",
      "45.019728342692055\n",
      "43.717020670572914\n",
      "49.76900668591743\n",
      "44.010011228542886\n",
      "46.8904308825249\n",
      "44.20531504362532\n",
      "39.67853916501536\n",
      "48.596533062388595\n",
      "40.85397448740345\n",
      "43.21477100532803\n",
      "47.35982501082436\n",
      "47.28557376799846\n",
      "47.03705474705372\n",
      "44.21387180464168\n",
      "43.376735020609736\n",
      "43.84465374992889\n",
      "47.14801629075726\n"
     ]
    }
   ],
   "source": [
    "runs = 50\n",
    "epochs = 50\n",
    "mse_list = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=i)\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    meansqrerror = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(meansqrerror)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean is  57.503335242856345\n",
      "The standard devation is 20.701047243657158\n"
     ]
    }
   ],
   "source": [
    "mse_list = np.array(mse_list)\n",
    "mean = np.mean(mse_list)\n",
    "standard_deviation = np.std(mse_list)\n",
    "\n",
    "print(\"the mean is \", mean)\n",
    "print(\"The standard devation is\", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean significantly decreases as with the standard deviation and the mean squared error values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 hidden layers each with 10 nodes using the relu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part D\n",
    "def regression_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 309 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 1720.4617 - val_loss: 1240.9627\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1703.0194 - val_loss: 1229.1944\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1686.3609 - val_loss: 1214.8792\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1662.6368 - val_loss: 1193.0260\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1625.3897 - val_loss: 1159.9383\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1568.0023 - val_loss: 1107.6606\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1473.0050 - val_loss: 1028.0471\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1324.6144 - val_loss: 906.3575\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1105.9571 - val_loss: 737.6668\n",
      "Epoch 10/100\n",
      " - 0s - loss: 825.3170 - val_loss: 541.4419\n",
      "Epoch 11/100\n",
      " - 0s - loss: 554.9121 - val_loss: 366.9957\n",
      "Epoch 12/100\n",
      " - 0s - loss: 380.3667 - val_loss: 249.4000\n",
      "Epoch 13/100\n",
      " - 0s - loss: 307.4641 - val_loss: 196.6887\n",
      "Epoch 14/100\n",
      " - 0s - loss: 272.6433 - val_loss: 170.5095\n",
      "Epoch 15/100\n",
      " - 0s - loss: 250.8343 - val_loss: 156.9344\n",
      "Epoch 16/100\n",
      " - 0s - loss: 234.7007 - val_loss: 148.4473\n",
      "Epoch 17/100\n",
      " - 0s - loss: 220.5798 - val_loss: 140.6414\n",
      "Epoch 18/100\n",
      " - 0s - loss: 210.3522 - val_loss: 135.9979\n",
      "Epoch 19/100\n",
      " - 0s - loss: 201.2539 - val_loss: 133.1811\n",
      "Epoch 20/100\n",
      " - 0s - loss: 193.4638 - val_loss: 130.4511\n",
      "Epoch 21/100\n",
      " - 0s - loss: 186.9043 - val_loss: 130.4063\n",
      "Epoch 22/100\n",
      " - 0s - loss: 181.6704 - val_loss: 128.0190\n",
      "Epoch 23/100\n",
      " - 0s - loss: 176.6219 - val_loss: 126.0411\n",
      "Epoch 24/100\n",
      " - 0s - loss: 172.6448 - val_loss: 124.2996\n",
      "Epoch 25/100\n",
      " - 0s - loss: 169.1861 - val_loss: 124.2980\n",
      "Epoch 26/100\n",
      " - 0s - loss: 165.9728 - val_loss: 124.2562\n",
      "Epoch 27/100\n",
      " - 0s - loss: 163.0624 - val_loss: 122.9800\n",
      "Epoch 28/100\n",
      " - 0s - loss: 160.7560 - val_loss: 120.9521\n",
      "Epoch 29/100\n",
      " - 0s - loss: 157.9654 - val_loss: 122.2902\n",
      "Epoch 30/100\n",
      " - 0s - loss: 155.9742 - val_loss: 121.7670\n",
      "Epoch 31/100\n",
      " - 0s - loss: 154.1535 - val_loss: 121.5901\n",
      "Epoch 32/100\n",
      " - 0s - loss: 152.3267 - val_loss: 118.9606\n",
      "Epoch 33/100\n",
      " - 0s - loss: 150.3891 - val_loss: 119.1846\n",
      "Epoch 34/100\n",
      " - 0s - loss: 149.0667 - val_loss: 118.9479\n",
      "Epoch 35/100\n",
      " - 0s - loss: 147.0688 - val_loss: 118.6744\n",
      "Epoch 36/100\n",
      " - 0s - loss: 145.7888 - val_loss: 119.0629\n",
      "Epoch 37/100\n",
      " - 0s - loss: 144.6523 - val_loss: 117.9476\n",
      "Epoch 38/100\n",
      " - 0s - loss: 143.1041 - val_loss: 118.7311\n",
      "Epoch 39/100\n",
      " - 0s - loss: 142.7767 - val_loss: 118.8216\n",
      "Epoch 40/100\n",
      " - 0s - loss: 141.5762 - val_loss: 118.5097\n",
      "Epoch 41/100\n",
      " - 0s - loss: 140.6499 - val_loss: 117.5192\n",
      "Epoch 42/100\n",
      " - 0s - loss: 139.5705 - val_loss: 117.8060\n",
      "Epoch 43/100\n",
      " - 0s - loss: 138.7804 - val_loss: 117.6631\n",
      "Epoch 44/100\n",
      " - 0s - loss: 137.8209 - val_loss: 117.1351\n",
      "Epoch 45/100\n",
      " - 0s - loss: 137.0319 - val_loss: 116.7362\n",
      "Epoch 46/100\n",
      " - 0s - loss: 136.4609 - val_loss: 118.1287\n",
      "Epoch 47/100\n",
      " - 0s - loss: 135.5666 - val_loss: 116.9279\n",
      "Epoch 48/100\n",
      " - 0s - loss: 135.0956 - val_loss: 116.2592\n",
      "Epoch 49/100\n",
      " - 0s - loss: 134.0346 - val_loss: 117.2797\n",
      "Epoch 50/100\n",
      " - 0s - loss: 133.3103 - val_loss: 116.7993\n",
      "Epoch 51/100\n",
      " - 0s - loss: 132.2454 - val_loss: 116.3712\n",
      "Epoch 52/100\n",
      " - 0s - loss: 131.4670 - val_loss: 114.8200\n",
      "Epoch 53/100\n",
      " - 0s - loss: 130.5712 - val_loss: 115.5563\n",
      "Epoch 54/100\n",
      " - 0s - loss: 130.0183 - val_loss: 115.0505\n",
      "Epoch 55/100\n",
      " - 0s - loss: 129.1312 - val_loss: 115.1056\n",
      "Epoch 56/100\n",
      " - 0s - loss: 128.2986 - val_loss: 115.5886\n",
      "Epoch 57/100\n",
      " - 0s - loss: 127.7345 - val_loss: 114.8866\n",
      "Epoch 58/100\n",
      " - 0s - loss: 127.2049 - val_loss: 116.5230\n",
      "Epoch 59/100\n",
      " - 0s - loss: 126.7041 - val_loss: 116.7769\n",
      "Epoch 60/100\n",
      " - 0s - loss: 125.8598 - val_loss: 117.7042\n",
      "Epoch 61/100\n",
      " - 0s - loss: 124.9840 - val_loss: 117.5450\n",
      "Epoch 62/100\n",
      " - 0s - loss: 124.4304 - val_loss: 116.8800\n",
      "Epoch 63/100\n",
      " - 0s - loss: 123.4229 - val_loss: 117.3316\n",
      "Epoch 64/100\n",
      " - 0s - loss: 123.1393 - val_loss: 117.7695\n",
      "Epoch 65/100\n",
      " - 0s - loss: 121.6378 - val_loss: 118.0058\n",
      "Epoch 66/100\n",
      " - 0s - loss: 121.3542 - val_loss: 118.2828\n",
      "Epoch 67/100\n",
      " - 0s - loss: 120.9827 - val_loss: 119.1063\n",
      "Epoch 68/100\n",
      " - 0s - loss: 119.7523 - val_loss: 118.6164\n",
      "Epoch 69/100\n",
      " - 0s - loss: 118.8872 - val_loss: 118.8950\n",
      "Epoch 70/100\n",
      " - 0s - loss: 118.4559 - val_loss: 118.8844\n",
      "Epoch 71/100\n",
      " - 0s - loss: 117.4802 - val_loss: 117.9891\n",
      "Epoch 72/100\n",
      " - 0s - loss: 117.0374 - val_loss: 121.3483\n",
      "Epoch 73/100\n",
      " - 0s - loss: 116.7165 - val_loss: 119.7047\n",
      "Epoch 74/100\n",
      " - 0s - loss: 115.6495 - val_loss: 120.4316\n",
      "Epoch 75/100\n",
      " - 0s - loss: 114.8833 - val_loss: 119.8795\n",
      "Epoch 76/100\n",
      " - 0s - loss: 114.0633 - val_loss: 120.7462\n",
      "Epoch 77/100\n",
      " - 0s - loss: 113.5156 - val_loss: 119.9237\n",
      "Epoch 78/100\n",
      " - 0s - loss: 112.5687 - val_loss: 120.6851\n",
      "Epoch 79/100\n",
      " - 0s - loss: 112.2403 - val_loss: 120.6246\n",
      "Epoch 80/100\n",
      " - 0s - loss: 110.5405 - val_loss: 119.0207\n",
      "Epoch 81/100\n",
      " - 0s - loss: 109.5507 - val_loss: 119.7963\n",
      "Epoch 82/100\n",
      " - 0s - loss: 108.6313 - val_loss: 120.5007\n",
      "Epoch 83/100\n",
      " - 0s - loss: 107.7215 - val_loss: 119.9694\n",
      "Epoch 84/100\n",
      " - 0s - loss: 106.6799 - val_loss: 120.5204\n",
      "Epoch 85/100\n",
      " - 0s - loss: 105.7585 - val_loss: 120.0091\n",
      "Epoch 86/100\n",
      " - 0s - loss: 105.3956 - val_loss: 119.7494\n",
      "Epoch 87/100\n",
      " - 0s - loss: 104.1671 - val_loss: 118.5227\n",
      "Epoch 88/100\n",
      " - 0s - loss: 102.9402 - val_loss: 120.4414\n",
      "Epoch 89/100\n",
      " - 0s - loss: 101.6928 - val_loss: 119.7867\n",
      "Epoch 90/100\n",
      " - 0s - loss: 100.6648 - val_loss: 118.0147\n",
      "Epoch 91/100\n",
      " - 0s - loss: 99.5146 - val_loss: 119.3167\n",
      "Epoch 92/100\n",
      " - 0s - loss: 98.3243 - val_loss: 118.0981\n",
      "Epoch 93/100\n",
      " - 0s - loss: 97.1518 - val_loss: 118.9456\n",
      "Epoch 94/100\n",
      " - 0s - loss: 95.9580 - val_loss: 117.3335\n",
      "Epoch 95/100\n",
      " - 0s - loss: 94.6317 - val_loss: 119.3107\n",
      "Epoch 96/100\n",
      " - 0s - loss: 93.0007 - val_loss: 117.2070\n",
      "Epoch 97/100\n",
      " - 0s - loss: 91.7666 - val_loss: 117.6443\n",
      "Epoch 98/100\n",
      " - 0s - loss: 89.8910 - val_loss: 119.5902\n",
      "Epoch 99/100\n",
      " - 0s - loss: 88.5598 - val_loss: 119.2350\n",
      "Epoch 100/100\n",
      " - 0s - loss: 86.8796 - val_loss: 115.1695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1d7d40470>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = regression_model()\n",
    "model.fit(predictors_norm, target, validation_split=0.3, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "721/721 [==============================] - 0s 351us/step - loss: 1503.3931\n",
      "Epoch 2/50\n",
      "721/721 [==============================] - 0s 29us/step - loss: 1442.4334\n",
      "Epoch 3/50\n",
      "721/721 [==============================] - 0s 32us/step - loss: 1356.2400\n",
      "Epoch 4/50\n",
      "721/721 [==============================] - 0s 32us/step - loss: 1236.7162\n",
      "Epoch 5/50\n",
      "721/721 [==============================] - 0s 37us/step - loss: 1078.2621\n",
      "Epoch 6/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 890.0668\n",
      "Epoch 7/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 693.7974\n",
      "Epoch 8/50\n",
      "721/721 [==============================] - 0s 32us/step - loss: 525.4517\n",
      "Epoch 9/50\n",
      "721/721 [==============================] - 0s 33us/step - loss: 407.3106\n",
      "Epoch 10/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 327.4502\n",
      "Epoch 11/50\n",
      "721/721 [==============================] - 0s 33us/step - loss: 284.5710\n",
      "Epoch 12/50\n",
      "721/721 [==============================] - 0s 42us/step - loss: 257.3462\n",
      "Epoch 13/50\n",
      "721/721 [==============================] - 0s 37us/step - loss: 240.4813\n",
      "Epoch 14/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 227.9330\n",
      "Epoch 15/50\n",
      "721/721 [==============================] - 0s 39us/step - loss: 218.2188\n",
      "Epoch 16/50\n",
      "721/721 [==============================] - 0s 39us/step - loss: 210.8876\n",
      "Epoch 17/50\n",
      "721/721 [==============================] - 0s 37us/step - loss: 202.3362\n",
      "Epoch 18/50\n",
      "721/721 [==============================] - 0s 42us/step - loss: 196.0088\n",
      "Epoch 19/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 190.2873\n",
      "Epoch 20/50\n",
      "721/721 [==============================] - 0s 39us/step - loss: 185.5284\n",
      "Epoch 21/50\n",
      "721/721 [==============================] - 0s 42us/step - loss: 181.1965\n",
      "Epoch 22/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 177.2225\n",
      "Epoch 23/50\n",
      "721/721 [==============================] - 0s 47us/step - loss: 173.4278\n",
      "Epoch 24/50\n",
      "721/721 [==============================] - 0s 50us/step - loss: 169.8146\n",
      "Epoch 25/50\n",
      "721/721 [==============================] - 0s 85us/step - loss: 166.8094\n",
      "Epoch 26/50\n",
      "721/721 [==============================] - 0s 42us/step - loss: 163.4660\n",
      "Epoch 27/50\n",
      "721/721 [==============================] - 0s 39us/step - loss: 160.8520\n",
      "Epoch 28/50\n",
      "721/721 [==============================] - 0s 42us/step - loss: 157.7253\n",
      "Epoch 29/50\n",
      "721/721 [==============================] - 0s 37us/step - loss: 154.9910\n",
      "Epoch 30/50\n",
      "721/721 [==============================] - 0s 40us/step - loss: 152.9717\n",
      "Epoch 31/50\n",
      "721/721 [==============================] - 0s 40us/step - loss: 150.6763\n",
      "Epoch 32/50\n",
      "721/721 [==============================] - 0s 55us/step - loss: 148.5988\n",
      "Epoch 33/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 146.0333\n",
      "Epoch 34/50\n",
      "721/721 [==============================] - 0s 40us/step - loss: 144.1957\n",
      "Epoch 35/50\n",
      "721/721 [==============================] - 0s 33us/step - loss: 142.3315\n",
      "Epoch 36/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 140.4458\n",
      "Epoch 37/50\n",
      "721/721 [==============================] - 0s 33us/step - loss: 139.4811\n",
      "Epoch 38/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 136.8158\n",
      "Epoch 39/50\n",
      "721/721 [==============================] - 0s 36us/step - loss: 135.3222\n",
      "Epoch 40/50\n",
      "721/721 [==============================] - 0s 37us/step - loss: 134.2263\n",
      "Epoch 41/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 132.2803\n",
      "Epoch 42/50\n",
      "721/721 [==============================] - 0s 32us/step - loss: 131.2589\n",
      "Epoch 43/50\n",
      "721/721 [==============================] - 0s 36us/step - loss: 129.7318\n",
      "Epoch 44/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 128.6882\n",
      "Epoch 45/50\n",
      "721/721 [==============================] - 0s 33us/step - loss: 127.1436\n",
      "Epoch 46/50\n",
      "721/721 [==============================] - 0s 32us/step - loss: 125.9439\n",
      "Epoch 47/50\n",
      "721/721 [==============================] - 0s 44us/step - loss: 125.0793\n",
      "Epoch 48/50\n",
      "721/721 [==============================] - 0s 33us/step - loss: 123.8983\n",
      "Epoch 49/50\n",
      "721/721 [==============================] - 0s 32us/step - loss: 123.0702\n",
      "Epoch 50/50\n",
      "721/721 [==============================] - 0s 35us/step - loss: 121.7390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f1d8319cf8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)\n",
    "model = regression_model()\n",
    "epochs = 50\n",
    "model.fit(X_train, y_train, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 369us/step\n",
      "Loss value is 123.98904836216406\n",
      "The mean is  123.98905553118564 The standard deviation is  0.0\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Loss value is\", loss)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mean = np.mean(mse)\n",
    "standard_deviation = np.std(mse)\n",
    "print(\"The mean is \", mean, \"The standard deviation is \", standard_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.44995850498236\n",
      "69.84756146279739\n",
      "49.98713223602394\n",
      "46.144731256182524\n",
      "40.71396296232649\n",
      "39.32934587595918\n",
      "40.70256835048639\n",
      "30.453140771118953\n",
      "32.86790214464502\n",
      "33.33833857415949\n",
      "28.213283057351713\n",
      "23.66947286414483\n",
      "31.980330016620723\n",
      "36.31943353943068\n",
      "25.13825224595548\n",
      "24.30069088241429\n",
      "25.958623133045183\n",
      "29.951032706448945\n",
      "25.946467217504015\n",
      "28.299402860376055\n",
      "27.136154637753386\n",
      "23.334755949989493\n",
      "22.225519433376473\n",
      "24.893499633640918\n",
      "25.16235930557004\n",
      "24.451569838045483\n",
      "20.74531986026702\n",
      "20.994991376562027\n",
      "26.59633700670162\n",
      "22.66712231929248\n",
      "18.43279756465776\n",
      "20.25903124639517\n",
      "20.664573370060104\n",
      "22.14330687723499\n",
      "23.489950741764797\n",
      "27.10523702565906\n",
      "18.12076645761632\n",
      "21.121240399802\n",
      "22.569103370592433\n",
      "20.180229446262988\n",
      "24.421202934289827\n",
      "20.30978528735707\n",
      "22.288792576218885\n",
      "25.201778634080608\n",
      "25.000005345514293\n",
      "18.963539888943668\n",
      "21.794826544604256\n",
      "20.165684227804537\n",
      "20.441370127656313\n",
      "21.317861291582915\n"
     ]
    }
   ],
   "source": [
    "runs = 50\n",
    "epochs = 50\n",
    "mse_list = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=i)\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    meansqrerror = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(meansqrerror)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean is  28.31620657173715\n",
      "The standard devation is 11.896806705281353\n"
     ]
    }
   ],
   "source": [
    "mse_list = np.array(mse_list)\n",
    "mean = np.mean(mse_list)\n",
    "standard_deviation = np.std(mse_list)\n",
    "\n",
    "print(\"the mean is \", mean)\n",
    "print(\"The standard devation is\", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values are much lower and more accurate than in the previous parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
